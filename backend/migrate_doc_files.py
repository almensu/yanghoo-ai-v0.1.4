#!/usr/bin/env python3
"""
æ•°æ®è¿ç§»è„šæœ¬ï¼šå°†çŽ°æœ‰çš„mdæ–‡æ¡£è·¯å¾„è½¬æ¢ä¸ºdoc_filesç»“æž„
ç”¨äºŽæ”¯æŒé¡¹ç›®ç¯®çš„å®Œæ•´æº¯æºåŠŸèƒ½
"""

import json
import os
from datetime import datetime
from pathlib import Path

METADATA_FILE = 'backend/data/metadata.json'
BACKUP_FILE = 'backend/data/metadata_backup_before_doc_files_migration.json'

def load_metadata():
    """åŠ è½½metadata.jsonæ–‡ä»¶"""
    try:
        with open(METADATA_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Error: {METADATA_FILE} not found")
        return None
    except json.JSONDecodeError as e:
        print(f"Error: Invalid JSON in {METADATA_FILE}: {e}")
        return None

def save_metadata(metadata):
    """ä¿å­˜metadata.jsonæ–‡ä»¶"""
    try:
        with open(METADATA_FILE, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"Error saving metadata: {e}")
        return False

def backup_metadata(metadata):
    """å¤‡ä»½åŽŸå§‹metadataæ–‡ä»¶"""
    try:
        with open(BACKUP_FILE, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        print(f"âœ… åŽŸå§‹metadataå·²å¤‡ä»½åˆ°: {BACKUP_FILE}")
        return True
    except Exception as e:
        print(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
        return False

def get_file_info(file_path):
    """èŽ·å–æ–‡ä»¶ä¿¡æ¯"""
    full_path = f"backend/data/{file_path}"
    try:
        if os.path.exists(full_path):
            stat = os.stat(full_path)
            return {
                'size': stat.st_size,
                'created_at': datetime.fromtimestamp(stat.st_ctime).isoformat(),
                'last_modified': datetime.fromtimestamp(stat.st_mtime).isoformat()
            }
    except:
        pass
    
    return {
        'size': None,
        'created_at': None,
        'last_modified': None
    }

def migrate_task_documents(task_uuid, task_data):
    """è¿ç§»å•ä¸ªä»»åŠ¡çš„æ–‡æ¡£"""
    print(f"ðŸ“‹ è¿ç§»ä»»åŠ¡: {task_data.get('title', 'Unknown')} ({task_uuid[:8]}...)")
    
    # å¦‚æžœå·²ç»æœ‰doc_filesç»“æž„ï¼Œè·³è¿‡
    if 'doc_files' in task_data:
        print("  â­ï¸  å·²å­˜åœ¨doc_filesç»“æž„ï¼Œè·³è¿‡")
        return task_data, 0
    
    # åˆå§‹åŒ–doc_filesç»“æž„
    doc_files = {
        'transcripts': {},
        'analysis': {},
        'user_documents': {},
        'system_generated': {}
    }
    
    migrated_count = 0
    
    # æ˜ å°„æ—§å­—æ®µåˆ°æ–°çš„doc_filesç»“æž„
    document_mappings = [
        # è½¬å½•æ–‡æ¡£
        ('parallel_vtt_md_path', 'transcripts', 'parallel_transcript_vtt.md', 'transcript', 'bilingual', 'vtt_based'),
        ('merged_format_vtt_md_path', 'transcripts', 'merged_transcript_vtt.md', 'transcript', 'bilingual', 'vtt_based'),
        ('en_only_vtt_md_path', 'transcripts', 'en_transcript_vtt.md', 'transcript', 'english', 'vtt_based'),
        ('zh_only_vtt_md_path', 'transcripts', 'zh_transcript_vtt.md', 'transcript', 'chinese', 'vtt_based'),
        ('en_only_vtt_timestamp_md_path', 'transcripts', 'en_transcript_vtt_timestamp.md', 'transcript', 'english', 'vtt_timestamp'),
        ('zh_only_vtt_timestamp_md_path', 'transcripts', 'zh_transcript_vtt_timestamp.md', 'transcript', 'chinese', 'vtt_timestamp'),
        ('merged_whisperx_md_path', 'transcripts', 'merged_whisperx.md', 'transcript', 'bilingual', 'whisperx_based'),
        
        # SRTè½¬å½•æ–‡æ¡£ (å¦‚æžœå­˜åœ¨srt_md_files)
        ('srt_md_files', 'transcripts', None, 'transcript', 'various', 'srt_based'),
    ]
    
    for old_field, category, default_filename, doc_category, language, format_type in document_mappings:
        if old_field in task_data and task_data[old_field]:
            if old_field == 'srt_md_files' and isinstance(task_data[old_field], dict):
                # å¤„ç†srt_md_fileså­—å…¸
                for srt_key, srt_path in task_data[old_field].items():
                    if srt_path:
                        filename = f"{srt_key}_transcript_srt.md"
                        file_info = get_file_info(srt_path)
                        
                        doc_files[category][filename] = {
                            'path': srt_path,
                            'type': 'markdown',
                            'category': doc_category,
                            'language': srt_key.replace('_', ' '),
                            'format': format_type,
                            'created_at': file_info['created_at'] or task_data.get('created_at'),
                            'last_modified': file_info['last_modified'] or task_data.get('last_modified'),
                            'size': file_info['size'],
                            'blocks_count': None,
                            'description': f"SRT-based transcript in {srt_key.replace('_', ' ')} format"
                        }
                        migrated_count += 1
                        print(f"  âœ… è¿ç§»SRTæ–‡æ¡£: {filename}")
            else:
                # å¤„ç†å•ä¸ªè·¯å¾„å­—æ®µ
                file_path = task_data[old_field]
                if file_path and default_filename:
                    file_info = get_file_info(file_path)
                    
                    doc_files[category][default_filename] = {
                        'path': file_path,
                        'type': 'markdown',
                        'category': doc_category,
                        'language': language,
                        'format': format_type,
                        'created_at': file_info['created_at'] or task_data.get('created_at'),
                        'last_modified': file_info['last_modified'] or task_data.get('last_modified'),
                        'size': file_info['size'],
                        'blocks_count': None,
                        'description': f"{language.title()} transcript in {format_type.replace('_', ' ')} format"
                    }
                    migrated_count += 1
                    print(f"  âœ… è¿ç§»æ–‡æ¡£: {default_filename}")
    
    # æ·»åŠ doc_filesåˆ°ä»»åŠ¡æ•°æ®
    if migrated_count > 0:
        task_data['doc_files'] = doc_files
        print(f"  ðŸ“Š æ€»è®¡è¿ç§» {migrated_count} ä¸ªæ–‡æ¡£")
    else:
        print("  â„¹ï¸  æ²¡æœ‰æ‰¾åˆ°å¯è¿ç§»çš„æ–‡æ¡£")
    
    return task_data, migrated_count

def main():
    """ä¸»è¿ç§»å‡½æ•°"""
    print("ðŸš€ å¼€å§‹doc_filesæ•°æ®è¿ç§»...")
    print("=" * 50)
    
    # åŠ è½½åŽŸå§‹æ•°æ®
    metadata = load_metadata()
    if metadata is None:
        return False
    
    print(f"ðŸ“ åŠ è½½äº† {len(metadata)} ä¸ªä»»åŠ¡")
    
    # å¤‡ä»½åŽŸå§‹æ•°æ®
    if not backup_metadata(metadata):
        return False
    
    # æ‰§è¡Œè¿ç§»
    total_migrated = 0
    total_tasks = len(metadata)
    
    for task_uuid, task_data in metadata.items():
        try:
            updated_task_data, migrated_count = migrate_task_documents(task_uuid, task_data)
            metadata[task_uuid] = updated_task_data
            total_migrated += migrated_count
        except Exception as e:
            print(f"âŒ è¿ç§»ä»»åŠ¡ {task_uuid[:8]}... å¤±è´¥: {e}")
            continue
    
    print("=" * 50)
    print(f"ðŸ“Š è¿ç§»ç»Ÿè®¡:")
    print(f"  - æ€»ä»»åŠ¡æ•°: {total_tasks}")
    print(f"  - æ€»è¿ç§»æ–‡æ¡£æ•°: {total_migrated}")
    
    # ä¿å­˜è¿ç§»åŽçš„æ•°æ®
    if save_metadata(metadata):
        print("âœ… è¿ç§»å®Œæˆï¼æ–°çš„metadata.jsonå·²ä¿å­˜")
        print(f"ðŸ’¡ å¦‚æžœéœ€è¦å›žæ»šï¼Œè¯·ä½¿ç”¨: {BACKUP_FILE}")
        return True
    else:
        print("âŒ ä¿å­˜è¿ç§»åŽçš„æ•°æ®å¤±è´¥")
        return False

def rollback():
    """å›žæ»šè¿ç§»"""
    print("ðŸ”„ å¼€å§‹å›žæ»šè¿ç§»...")
    
    if not os.path.exists(BACKUP_FILE):
        print(f"âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {BACKUP_FILE}")
        return False
    
    try:
        # æ¢å¤å¤‡ä»½
        with open(BACKUP_FILE, 'r', encoding='utf-8') as f:
            backup_data = json.load(f)
        
        with open(METADATA_FILE, 'w', encoding='utf-8') as f:
            json.dump(backup_data, f, ensure_ascii=False, indent=2)
        
        print("âœ… å›žæ»šå®Œæˆï¼å·²æ¢å¤åˆ°è¿ç§»å‰çŠ¶æ€")
        return True
    except Exception as e:
        print(f"âŒ å›žæ»šå¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == 'rollback':
        rollback()
    else:
        main() 